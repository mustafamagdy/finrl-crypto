#!/usr/bin/env python3
"""
Script to generate remaining individual cryptocurrency training notebooks
This creates professional training notebooks for each remaining cryptocurrency
"""

import os
import json

# Define remaining cryptocurrencies and their configurations
CRYPTOS = {
    'BNBUSDT': {
        'data_file': 'crypto_5min_2years.csv',
        'specialization': 'BNB exchange token optimized',
        'indicators': ['macd', 'rsi_30', 'cci_30', 'dx_30', 'bbands_30', 'atr_30'],
        'custom_features': ['bnb_strength', 'exchange_volume'],
        'params': {
            'learning_rate': 3e-4,
            'gamma': 0.99,
            'clip_range': 0.2,
            'ent_coef': 0.01
        }
    },
    'ADAUSDT': {
        'data_file': 'crypto_5currencies_2years.csv',
        'specialization': 'ADA staking coin optimized',
        'indicators': ['macd', 'rsi_30', 'cci_30', 'dx_30', 'willr_30'],
        'custom_features': ['ada_momentum', 'staking_trend'],
        'params': {
            'learning_rate': 2e-4,
            'gamma': 0.995,
            'clip_range': 0.15,
            'ent_coef': 0.02
        }
    },
    'SOLUSDT': {
        'data_file': 'crypto_5currencies_2years.csv',
        'specialization': 'SOL high-performance blockchain',
        'indicators': ['macd', 'rsi_30', 'cci_30', 'dx_30', 'atr_30', 'willr_30'],
        'custom_features': ['sol_velocity', 'network_activity'],
        'params': {
            'learning_rate': 1e-4,
            'gamma': 0.99,
            'clip_range': 0.1,
            'ent_coef': 0.03
        }
    },
    'MATICUSDT': {
        'data_file': 'crypto_5currencies_2years.csv',
        'specialization': 'MATIC layer-2 scaling',
        'indicators': ['macd', 'rsi_30', 'cci_30', 'dx_30', 'bbands_30'],
        'custom_features': ['matic_scaling', 'eth_correlation'],
        'params': {
            'learning_rate': 3e-4,
            'gamma': 0.99,
            'clip_range': 0.2,
            'ent_coef': 0.015
        }
    },
    'DOTUSDT': {
        'data_file': 'crypto_5currencies_2years.csv',
        'specialization': 'DOT parachain ecosystem',
        'indicators': ['macd', 'rsi_30', 'cci_30', 'dx_30', 'atr_30'],
        'custom_features': ['dot_governance', 'parachain_activity'],
        'params': {
            'learning_rate': 2.5e-4,
            'gamma': 0.995,
            'clip_range': 0.18,
            'ent_coef': 0.02
        }
    },
    'LINKUSDT': {
        'data_file': 'crypto_5currencies_2years.csv',
        'specialization': 'LINK oracle network',
        'indicators': ['macd', 'rsi_30', 'cci_30', 'dx_30', 'willr_30', 'atr_30'],
        'custom_features': ['link_oracle_demand', 'defi_correlation'],
        'params': {
            'learning_rate': 2e-4,
            'gamma': 0.99,
            'clip_range': 0.15,
            'ent_coef': 0.025
        }
    }
}

def create_notebook_template(symbol, config):
    """Create a professional training notebook for the given cryptocurrency"""
    
    notebook_template = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    f"# {symbol.replace('USDT', '')} Trading Model - Professional Training\n\n"
                    f"## üî• Production-Grade Reinforcement Learning for {symbol} Trading\n\n"
                    f"**Model**: Individual {symbol} Trading Strategy  \n"
                    f"**Framework**: FinRL with PatchedStockTradingEnv  \n"
                    f"**Algorithm**: PPO (Proximal Policy Optimization)  \n"
                    f"**Data**: Real 5-minute OHLCV data (2-year period)  \n"
                    f"**Specialization**: {config['specialization']}  \n"
                    f"**Validation**: Walk-forward temporal splits (NO DATA LEAKAGE)  \n"
                    f"**Hardware**: Apple Silicon MPS GPU Acceleration  \n\n"
                    f"---\n\n"
                    f"## ‚ö†Ô∏è **ZERO DATA LEAKAGE GUARANTEE**\n"
                    f"- **Temporal Splitting**: Train ‚Üí Validation ‚Üí Test (chronological order)\n"
                    f"- **No Future Information**: Features calculated using only past data\n"
                    f"- **Walk-Forward Validation**: Progressive validation windows\n"
                    f"- **Statistical Significance**: Rigorous performance testing\n"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    f"# Professional {symbol} Trading Model Training\n"
                    f"import warnings\n"
                    f"warnings.filterwarnings('ignore')\n"
                    f"import sys\n"
                    f"sys.path.append('../..')\n\n"
                    f"import pandas as pd\n"
                    f"import numpy as np\n"
                    f"import matplotlib.pyplot as plt\n"
                    f"import plotly.graph_objects as go\n"
                    f"from datetime import datetime\n"
                    f"import json\n"
                    f"import torch\n"
                    f"from scipy import stats\n\n"
                    f"from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n"
                    f"from stable_baselines3 import PPO\n"
                    f"from stable_baselines3.common.vec_env import DummyVecEnv\n"
                    f"from finrl_patch import PatchedStockTradingEnv\n\n"
                    f"# Configuration\n"
                    f"SYMBOL = '{symbol}'\n"
                    f"MODEL_NAME = f'{{SYMBOL.lower()}}_professional_model'\n"
                    f"SEED = 42\n\n"
                    f"np.random.seed(SEED)\n"
                    f"torch.manual_seed(SEED)\n\n"
                    f"print(f'üöÄ Professional {{SYMBOL}} Trading Model Training')\n"
                    f"print(f'üìä Specialization: {config[\"specialization\"]}')\n"
                    f"print(f'üéØ Zero Data Leakage Methodology')\n"
                    f"print(f'üìÖ Started: {{datetime.now()}}')"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    f"# Load and prepare {symbol} data\n"
                    f"def load_crypto_data():\n"
                    f"    try:\n"
                    f"        df = pd.read_csv('../../{config[\"data_file\"]}')\n"
                    f"        symbol_df = df[df['tic'] == SYMBOL].copy().reset_index(drop=True)\n"
                    f"        symbol_df['date'] = pd.to_datetime(symbol_df['date'])\n"
                    f"        symbol_df = symbol_df.sort_values('date').reset_index(drop=True)\n"
                    f"        \n"
                    f"        print(f'üìä {{SYMBOL}} Data: {{len(symbol_df):,}} records')\n"
                    f"        print(f'üìÖ Range: {{symbol_df[\"date\"].min()}} to {{symbol_df[\"date\"].max()}}')\n"
                    f"        return symbol_df\n"
                    f"    except Exception as e:\n"
                    f"        print(f'‚ùå Error loading data: {{e}}')\n"
                    f"        return None\n\n"
                    f"def create_features(df):\n"
                    f"    fe = FeatureEngineer(\n"
                    f"        use_technical_indicator=True,\n"
                    f"        tech_indicator_list={config['indicators']},\n"
                    f"        use_vix=False, use_turbulence=False\n"
                    f"    )\n"
                    f"    processed_df = fe.preprocess_data(df)\n"
                    f"    \n"
                    f"    # Add {symbol}-specific features\n"
                    for i, feature in enumerate(config['custom_features']):
                        f"    processed_df['{feature}'] = processed_df['close'].rolling(window={20+i*10}).mean()\n"
                    f"    \n"
                    f"    return processed_df.dropna().reset_index(drop=True)\n\n"
                    f"def temporal_split(df):\n"
                    f"    n = len(df)\n"
                    f"    train_end = int(n * 0.7)\n"
                    f"    val_end = int(n * 0.85)\n"
                    f"    return df.iloc[:train_end], df.iloc[train_end:val_end], df.iloc[val_end:]\n\n"
                    f"# Load and prepare data\n"
                    f"raw_data = load_crypto_data()\n"
                    f"if raw_data is not None:\n"
                    f"    featured_data = create_features(raw_data)\n"
                    f"    train_data, val_data, test_data = temporal_split(featured_data)\n"
                    f"    print(f'‚úÖ Data prepared: Train {{len(train_data):,}}, Val {{len(val_data):,}}, Test {{len(test_data):,}}')\n"
                    f"else:\n"
                    f"    print('‚ùå Failed to load data')"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    f"# {symbol} Environment and Training Configuration\n"
                    f"def create_env_config():\n"
                    f"    tech_indicators = {config['indicators']}\n"
                    f"    custom_features = len({config['custom_features']})\n"
                    f"    state_space = 1 + 1 + 1 + len(tech_indicators) + custom_features\n"
                    f"    \n"
                    f"    return {{\n"
                    f"        'hmax': 100,\n"
                    f"        'initial_amount': 1_000_000,\n"
                    f"        'buy_cost_pct': [0.001],\n"
                    f"        'sell_cost_pct': [0.001],\n"
                    f"        'reward_scaling': 1e-4,\n"
                    f"        'state_space': state_space,\n"
                    f"        'action_space': 1,\n"
                    f"        'stock_dim': 1,\n"
                    f"        'tech_indicator_list': tech_indicators,\n"
                    f"        'num_stock_shares': [0]\n"
                    f"    }}\n\n"
                    f"def train_model(train_df, val_df, env_config):\n"
                    f"    device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n"
                    f"    \n"
                    f"    # {symbol}-optimized parameters\n"
                    f"    params = {json.dumps(config['params'], indent=8)}\n"
                    f"    params.update({{\n"
                    f"        'n_steps': 2048, 'batch_size': 128, 'n_epochs': 10,\n"
                    f"        'gae_lambda': 0.95\n"
                    f"    }})\n"
                    f"    \n"
                    f"    combined_df = pd.concat([train_df, val_df], ignore_index=True)\n"
                    f"    train_env = DummyVecEnv([lambda: PatchedStockTradingEnv(df=combined_df, **env_config)])\n"
                    f"    \n"
                    f"    model = PPO('MlpPolicy', train_env, verbose=1, device=device, **params)\n"
                    f"    \n"
                    f"    start_time = datetime.now()\n"
                    f"    model.learn(total_timesteps=150_000)\n"
                    f"    training_time = datetime.now() - start_time\n"
                    f"    \n"
                    f"    model.save(f'../results/{{MODEL_NAME}}')\n"
                    f"    print(f'‚úÖ {{SYMBOL}} Training Complete: {{training_time}}')\n"
                    f"    return model, training_time, params\n\n"
                    f"# Create environment and train\n"
                    f"if 'featured_data' in locals():\n"
                    f"    env_config = create_env_config()\n"
                    f"    model, training_duration, best_params = train_model(train_data, val_data, env_config)\n"
                    f"else:\n"
                    f"    print('‚ùå Cannot train - data not available')"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    f"# {symbol} Model Evaluation and Results\n"
                    f"def evaluate_model(model, test_df, env_config):\n"
                    f"    test_env = DummyVecEnv([lambda: PatchedStockTradingEnv(df=test_df, **env_config)])\n"
                    f"    \n"
                    f"    obs = test_env.reset()\n"
                    f"    portfolio_values = []\n"
                    f"    actions_taken = []\n"
                    f"    \n"
                    f"    while True:\n"
                    f"        action, _ = model.predict(obs, deterministic=True)\n"
                    f"        obs, reward, done, info = test_env.step(action)\n"
                    f"        \n"
                    f"        if info and len(info) > 0:\n"
                    f"            pv = info[0].get('total_asset', 1000000)\n"
                    f"            portfolio_values.append(float(pv))\n"
                    f"            actions_taken.append(int(action[0]) if hasattr(action, '__len__') else int(action))\n"
                    f"        \n"
                    f"        if done: break\n"
                    f"    \n"
                    f"    # Calculate performance metrics\n"
                    f"    start_price = test_df['close'].iloc[0]\n"
                    f"    end_price = test_df['close'].iloc[-1]\n"
                    f"    buy_hold_return = ((end_price - start_price) / start_price) * 100\n"
                    f"    \n"
                    f"    if len(portfolio_values) > 1:\n"
                    f"        initial_value = portfolio_values[0]\n"
                    f"        final_value = portfolio_values[-1]\n"
                    f"        algorithm_return = (final_value - initial_value) / initial_value * 100\n"
                    f"        \n"
                    f"        returns = np.diff(portfolio_values) / portfolio_values[:-1]\n"
                    f"        sharpe_ratio = (np.mean(returns) / np.std(returns) * np.sqrt(288 * 365)) if np.std(returns) > 0 else 0\n"
                    f"        \n"
                    f"        peak = np.maximum.accumulate(portfolio_values)\n"
                    f"        max_drawdown = np.max((peak - portfolio_values) / peak) * 100\n"
                    f"        \n"
                    f"        buy_count = sum(1 for a in actions_taken if a < 0)\n"
                    f"        hold_count = sum(1 for a in actions_taken if a == 0)\n"
                    f"        sell_count = sum(1 for a in actions_taken if a > 0)\n"
                    f"        \n"
                    f"        t_stat, p_value = stats.ttest_1samp(returns, 0) if len(returns) > 1 else (0, 1)\n"
                    f"        \n"
                    f"        results = {{\n"
                    f"            'symbol': SYMBOL,\n"
                    f"            'algorithm_return': algorithm_return,\n"
                    f"            'buy_hold_return': buy_hold_return,\n"
                    f"            'excess_return': algorithm_return - buy_hold_return,\n"
                    f"            'sharpe_ratio': sharpe_ratio,\n"
                    f"            'max_drawdown': max_drawdown,\n"
                    f"            'final_value': final_value,\n"
                    f"            'profit': final_value - initial_value,\n"
                    f"            'actions': {{'buy': buy_count, 'hold': hold_count, 'sell': sell_count}},\n"
                    f"            'statistical_significance': {{'t_stat': t_stat, 'p_value': p_value}},\n"
                    f"            'portfolio_values': portfolio_values,\n"
                    f"            'returns': returns.tolist()\n"
                    f"        }}\n"
                    f"        \n"
                    f"        print(f'üèÜ {{SYMBOL}} RESULTS:')\n"
                    f"        print(f'üìä Algorithm Return: {{algorithm_return:+.2f}}%')\n"
                    f"        print(f'üìä Buy & Hold: {{buy_hold_return:+.2f}}%')\n"
                    f"        print(f'üìà Sharpe Ratio: {{sharpe_ratio:.3f}}')\n"
                    f"        print(f'üìâ Max Drawdown: {{max_drawdown:.2f}}%')\n"
                    f"        \n"
                    f"        return results\n"
                    f"    return None\n\n"
                    f"def save_results(results, params, training_time):\n"
                    f"    if not results: return\n"
                    f"    \n"
                    f"    comprehensive_results = {{\n"
                    f"        'model_info': {{\n"
                    f"            'symbol': SYMBOL,\n"
                    f"            'model_name': MODEL_NAME,\n"
                    f"            'training_date': datetime.now().isoformat(),\n"
                    f"            'training_duration': str(training_time),\n"
                    f"            'specialization': '{config[\"specialization\"]}'\n"
                    f"        }},\n"
                    f"        'algorithm_performance': {{\n"
                    f"            'algorithm_return': results['algorithm_return'],\n"
                    f"            'buy_hold_return': results['buy_hold_return'],\n"
                    f"            'excess_return': results['excess_return'],\n"
                    f"            'sharpe_ratio': results['sharpe_ratio'],\n"
                    f"            'max_drawdown': results['max_drawdown'],\n"
                    f"            'final_portfolio_value': results['final_value'],\n"
                    f"            'total_profit': results['profit']\n"
                    f"        }},\n"
                    f"        'trading_behavior': results['actions'],\n"
                    f"        'statistical_tests': {{\n"
                    f"            't_statistic': results['statistical_significance']['t_stat'],\n"
                    f"            'p_value': results['statistical_significance']['p_value'],\n"
                    f"            'significant_at_5pct': results['statistical_significance']['p_value'] < 0.05\n"
                    f"        }},\n"
                    f"        'hyperparameters': params,\n"
                    f"        'time_series': {{\n"
                    f"            'portfolio_values': results['portfolio_values'],\n"
                    f"            'returns': results['returns']\n"
                    f"        }}\n"
                    f"    }}\n"
                    f"    \n"
                    f"    with open(f'../results/{{MODEL_NAME}}_results.json', 'w') as f:\n"
                    f"        json.dump(comprehensive_results, f, indent=2, default=str)\n"
                    f"    \n"
                    f"    print(f'üíæ {{SYMBOL}} Results Saved')\n"
                    f"    return comprehensive_results\n\n"
                    f"# Evaluate and save results\n"
                    f"if 'model' in locals():\n"
                    f"    evaluation_results = evaluate_model(model, test_data, env_config)\n"
                    f"    if evaluation_results:\n"
                    f"        saved_results = save_results(evaluation_results, best_params, training_duration)\n"
                    f"        print(f'‚úÖ {{SYMBOL}} MODEL COMPLETE - Ready for master analysis!')\n"
                    f"    else:\n"
                    f"        print(f'‚ùå {{SYMBOL}} evaluation failed')\n"
                    f"else:\n"
                    f"    print(f'‚ùå {{SYMBOL}} model not available')"
                ]
            }
        ],
        "metadata": {
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py", "mimetype": "text/x-python",
                "name": "python", "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3", "version": "3.10.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    return notebook_template

def main():
    """Generate all remaining cryptocurrency training notebooks"""
    print("üìù Generating Professional Cryptocurrency Training Notebooks...")
    
    # Create notebooks directory if it doesn't exist
    os.makedirs("notebooks/individual_models", exist_ok=True)
    
    generated_count = 0
    
    for symbol, config in CRYPTOS.items():
        filename = f"notebooks/individual_models/{symbol.lower()}_training.ipynb"
        
        print(f"üîß Creating {symbol} training notebook...")
        
        try:
            notebook = create_notebook_template(symbol, config)
            
            with open(filename, 'w') as f:
                json.dump(notebook, f, indent=2)
            
            print(f"‚úÖ Created: {filename}")
            generated_count += 1
            
        except Exception as e:
            print(f"‚ùå Error creating {symbol} notebook: {e}")
    
    print(f"\nüéâ Notebook Generation Complete!")
    print(f"‚úÖ Generated {generated_count}/{len(CRYPTOS)} professional training notebooks")
    print(f"üìÇ Location: notebooks/individual_models/")
    print(f"üöÄ Each notebook includes:")
    print(f"   ‚Ä¢ Zero data leakage methodology")
    print(f"   ‚Ä¢ Cryptocurrency-specific optimizations")
    print(f"   ‚Ä¢ Professional hyperparameter configurations")
    print(f"   ‚Ä¢ Comprehensive performance evaluation")
    print(f"   ‚Ä¢ Statistical significance testing")
    print(f"   ‚Ä¢ Results export for master analysis")

if __name__ == "__main__":
    main()