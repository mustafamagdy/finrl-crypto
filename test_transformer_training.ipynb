{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Transformer Training - TEST VERSION\n",
    "\n",
    "**Testing Model Saving Functionality**\n",
    "\n",
    "This is a test version with:\n",
    "- Small dataset for quick training\n",
    "- Fewer epochs\n",
    "- Robust saving mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install All Requirements for Enhanced Transformer Training\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"🚀 Installing Enhanced Transformer Requirements...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Update pip first\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install stable PyTorch version\n",
    "print(\"🔥 Installing PyTorch with GPU support...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install core ML libraries\n",
    "print(\"📊 Installing core ML libraries...\")\n",
    "!pip install numpy pandas scikit-learn matplotlib seaborn plotly\n",
    "\n",
    "# Install technical analysis libraries\n",
    "print(\"📈 Installing technical analysis libraries...\")\n",
    "!pip install ta talib-binary\n",
    "\n",
    "# Install utilities\n",
    "print(\"🔧 Installing utilities...\")\n",
    "!pip install tqdm psutil requests ipywidgets\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"✅ All requirements installed successfully!\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"🚀 Default device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(f\"💻 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "  print(f\"🧠 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "elif torch.backends.mps.is_available():\n",
    "  print(\"🍎 Apple Silicon GPU available\")\n",
    "else:\n",
    "  print(\"⚠️ No GPU detected, using CPU\")\n",
    "\n",
    "print(\"\\n🎯 Ready for enhanced transformer training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and handle PyTorch import issues\n",
    "import torch\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# Workaround for PyTorch import issues\n",
    "try:\n",
    "    from torch._utils_internal import justknobs_check\n",
    "except ImportError:\n",
    "    # Create a dummy function if the import fails\n",
    "    def justknobs_check(name, default=False):\n",
    "        return default\n",
    "\n",
    "# Fix for PyTorch 2.2+ pytree API changes\n",
    "try:\n",
    "    # Check if register_pytree_node exists\n",
    "    from torch.utils._pytree import register_pytree_node\n",
    "except ImportError:\n",
    "    # Apply monkey patch for older pytree API\n",
    "    import torch.utils._pytree as pytree\n",
    "    if not hasattr(pytree, 'register_pytree_node'):\n",
    "        def register_pytree_node(*args, **kwargs):\n",
    "            # Dummy implementation for compatibility\n",
    "            pass\n",
    "        pytree.register_pytree_node = register_pytree_node\n",
    "\n",
    "# Disable torch.compile to avoid more issues\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "print(f\"🔧 PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"💻 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"🧠 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy scikit-learn matplotlib ta talib-binary\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install stable-baselines3\n",
    "\n",
    "print(\"✅ Packages installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Data Loading and Preprocessing (Small Dataset for Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load cryptocurrency data\n",
    "def load_crypto_data(csv_path='sample_crypto_data.csv'):\n",
    "    \"\"\"Load and preprocess cryptocurrency data\"\"\"\n",
    "    print(f\"📊 Loading data from {csv_path}...\")\n",
    "    \n",
    "    # Create sample data for testing\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"🔧 Creating sample data for testing...\")\n",
    "        dates = pd.date_range(start='2024-01-01', periods=5000, freq='5T')\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Generate realistic price data\n",
    "        base_price = 50000\n",
    "        returns = np.random.normal(0, 0.001, 5000)\n",
    "        prices = [base_price]\n",
    "        \n",
    "        for ret in returns[1:]:\n",
    "            prices.append(prices[-1] * (1 + ret))\n",
    "        \n",
    "        prices = np.array(prices)\n",
    "        \n",
    "        sample_data = pd.DataFrame({\n",
    "            'tic': ['BTCUSDT'] * 5000,\n",
    "            'open': prices * (1 + np.random.normal(0, 0.0005, 5000)),\n",
    "            'high': prices * (1 + np.abs(np.random.normal(0, 0.001, 5000))),\n",
    "            'low': prices * (1 - np.abs(np.random.normal(0, 0.001, 5000))),\n",
    "            'close': prices,\n",
    "            'volume': np.random.uniform(100, 1000, 5000)\n",
    "        }, index=dates)\n",
    "        \n",
    "        sample_data.to_csv(csv_path)\n",
    "        df = sample_data\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"✅ Raw data shape: {df.shape}\")\n",
    "    \n",
    "    # Handle datetime index\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.set_index('date', inplace=True)\n",
    "    elif 'timestamp' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['timestamp'])\n",
    "        df.set_index('date', inplace=True)\n",
    "    else:\n",
    "        # Create datetime index for sample data\n",
    "        if len(df) > 0:\n",
    "            dates = pd.date_range(start='2024-01-01', periods=len(df), freq='5T')\n",
    "            df.index = dates\n",
    "    \n",
    "    print(f\"📅 Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"💰 Symbols: {df['tic'].unique() if 'tic' in df.columns else 'Unknown'}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "df = load_crypto_data()\n",
    "\n",
    "if df is not None:\n",
    "    display(df.head())\n",
    "    print(f\"\\n📋 Data info:\")\n",
    "    display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Enhanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import enhanced features module\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from enhanced_features import calculate_enhanced_features, select_important_features\n",
    "\n",
    "# Calculate enhanced features\n",
    "def process_features(df):\n",
    "    \"\"\"Process and enhance features for training\"\"\"\n",
    "    print(\"🔧 Calculating enhanced features...\")\n",
    "    \n",
    "    # Calculate enhanced features\n",
    "    enhanced_df = calculate_enhanced_features(df)\n",
    "    print(f\"✅ Enhanced features shape: {enhanced_df.shape}\")\n",
    "    \n",
    "    # Select important features\n",
    "    selected_features = select_important_features(enhanced_df, n_features=25)  # Reduced for testing\n",
    "    print(f\"🎯 Selected features shape: {selected_features.shape}\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    selected_features = selected_features.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "    \n",
    "    print(f\"✅ Final processed features shape: {selected_features.shape}\")\n",
    "    print(f\"📋 Feature columns: {list(selected_features.columns[:10])}...\")\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Process features\n",
    "if df is not None:\n",
    "    features_df = process_features(df)\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Enhanced Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import enhanced transformer\n",
    "from transformer_enhanced_v2 import EnhancedCryptoTransformer, create_enhanced_transformer_config\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create model configuration\n",
    "config = create_enhanced_transformer_config()\n",
    "# Modify config for testing\n",
    "config['model_params']['max_seq_len'] = 50  # Reduced for testing\n",
    "config['training_params']['n_epochs'] = 5  # Reduced for testing\n",
    "config['training_params']['batch_size'] = 16  # Reduced for testing\n",
    "\n",
    "print(\"📋 Model configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Create model\n",
    "if 'features_df' in locals():\n",
    "    input_dim = features_df.shape[1]\n",
    "    model = EnhancedCryptoTransformer(\n",
    "        input_dim=input_dim,\n",
    "        **config['model_params']\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\n🧠 Model created successfully!\")\n",
    "    print(f\"📊 Input dimension: {input_dim}\")\n",
    "    print(f\"🔧 Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"💾 Model size: {sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(\"⚠️ Features not available, creating test model\")\n",
    "    model = EnhancedCryptoTransformer(\n",
    "        input_dim=25,\n",
    "        **config['model_params']\n",
    "    ).to(device)\n",
    "    print(f\"🧠 Test model created with 25 input dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model forward pass\n",
    "def test_model(model, input_dim=25):\n",
    "    \"\"\"Test model forward pass\"\"\"\n",
    "    print(\"🧪 Testing model forward pass...\")\n",
    "    \n",
    "    # Create test input\n",
    "    batch_size = 4\n",
    "    seq_len = config['model_params']['max_seq_len']\n",
    "    test_input = torch.randn(batch_size, seq_len, input_dim).to(device)\n",
    "    \n",
    "    # Create multi-scale inputs\n",
    "    scale_inputs = {\n",
    "        5: torch.randn(batch_size, seq_len, input_dim).to(device),\n",
    "        15: torch.randn(batch_size, seq_len//3, input_dim).to(device),\n",
    "        30: torch.randn(batch_size, seq_len//6, input_dim).to(device),\n",
    "    }\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_input, scale_inputs)\n",
    "    \n",
    "    print(\"✅ Model forward pass successful!\")\n",
    "    print(\"📊 Output shapes:\")\n",
    "    for key, value in outputs.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"   {key}: {value.shape}\")\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Test model\n",
    "test_outputs = test_model(model, input_dim if 'features_df' in locals() else 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏋️‍♂️ Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "class CryptoDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for cryptocurrency trading\"\"\"\n",
    "    def __init__(self, features_df, sequence_length=50, prediction_horizon=5):\n",
    "        self.features = features_df.values\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.close_prices = features_df['close'].values if 'close' in features_df.columns else self.features[:, 0]\n",
    "        \n",
    "        self.sequences, self.targets = self._prepare_sequences()\n",
    "    \n",
    "    def _prepare_sequences(self):\n",
    "        \"\"\"Prepare training sequences\"\"\"\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        \n",
    "        for i in range(len(self.features) - self.sequence_length - self.prediction_horizon):\n",
    "            # Input sequence\n",
    "            seq = self.features[i:i + self.sequence_length]\n",
    "            sequences.append(seq)\n",
    "            \n",
    "            # Target (future return)\n",
    "            current_price = self.close_prices[i + self.sequence_length - 1]\n",
    "            future_price = self.close_prices[i + self.sequence_length + self.prediction_horizon - 1]\n",
    "            target_return = (future_price - current_price) / current_price\n",
    "            targets.append(target_return)\n",
    "        \n",
    "        return np.array(sequences), np.array(targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = torch.FloatTensor(self.sequences[idx])\n",
    "        target = torch.FloatTensor([self.targets[idx]])\n",
    "        return sequence, target\n",
    "\n",
    "# Create datasets\n",
    "if 'features_df' in locals():\n",
    "    print(\"🔧 Creating datasets...\")\n",
    "    \n",
    "    # Create dataset\n",
    "    full_dataset = CryptoDataset(features_df, sequence_length=config['model_params']['max_seq_len'])\n",
    "    \n",
    "    # Split data\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Training samples: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    batch_size = config['training_params']['batch_size']\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    print(f\"🔧 Batch size: {batch_size}\")\n",
    "    print(f\"🔧 Training batches: {len(train_loader)}\")\n",
    "    print(f\"🔧 Validation batches: {len(val_loader)}\")\n",
    "else:\n",
    "    print(\"⚠️ Features not available, skipping dataset creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Training Loop (Test Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Suppress PyTorch warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Initialize training components\n",
    "try:\n",
    "    if 'train_loader' in locals():\n",
    "        # Optimizer and scheduler\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config['training_params']['learning_rate'],\n",
    "            weight_decay=config['training_params']['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=config['training_params']['n_epochs'],\n",
    "            eta_min=config['training_params']['learning_rate'] * 0.1\n",
    "        )\n",
    "        \n",
    "        # Loss functions\n",
    "        action_loss_fn = nn.MSELoss()\n",
    "        confidence_loss_fn = nn.MSELoss()\n",
    "        \n",
    "        # Training history\n",
    "        training_history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'learning_rate': [],\n",
    "            'epoch_time': [],\n",
    "            'gpu_memory': []\n",
    "        }\n",
    "        \n",
    "        print(\"🚀 Training setup completed!\")\n",
    "    else:\n",
    "        print(\"⚠️ Training setup skipped - no datasets available\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error setting up training: {str(e)}\")\n",
    "    print(\"This might be due to PyTorch compatibility issues. Please restart the kernel and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    action_loss = 0\n",
    "    confidence_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences = sequences.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        \n",
    "        # Calculate losses\n",
    "        action_loss_batch = action_loss_fn(outputs['action'], targets)\n",
    "        confidence_loss_batch = confidence_loss_fn(outputs['confidence'], torch.ones_like(outputs['confidence']) * 0.8)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss_batch = action_loss_batch + 0.2 * confidence_loss_batch\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss_batch.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses\n",
    "        total_loss += total_loss_batch.item()\n",
    "        action_loss += action_loss_batch.item()\n",
    "        confidence_loss += confidence_loss_batch.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if batch_idx % 5 == 0:  # Reduced frequency for testing\n",
    "            print(f\"  Batch {batch_idx}/{len(train_loader)}: Loss = {total_loss_batch.item():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_loss': total_loss / num_batches,\n",
    "        'action_loss': action_loss / num_batches,\n",
    "        'confidence_loss': confidence_loss / num_batches\n",
    "    }\n",
    "\n",
    "def validate_epoch(model, val_loader, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in val_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(sequences)\n",
    "            \n",
    "            loss = action_loss_fn(outputs['action'], targets)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "print(\"🔧 Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "def start_training(model, train_loader, val_loader, optimizer, scheduler, config, device):\n",
    "    \"\"\"Start the training process\"\"\"\n",
    "    print(\"🚀 Starting enhanced transformer training (TEST VERSION)...\")\n",
    "    print(f\"📊 Training samples: {len(train_loader.dataset)}\")\n",
    "    print(f\"📊 Validation samples: {len(val_loader.dataset)}\")\n",
    "    print(f\"🧠 Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"🔧 Epochs: {config['training_params']['n_epochs']}\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    training_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'learning_rate': [],\n",
    "        'epoch_time': [],\n",
    "        'gpu_memory': []\n",
    "    }\n",
    "\n",
    "    # Fix PyTorch serialization issues\n",
    "    import pickle\n",
    "    import io\n",
    "    \n",
    "    class CPU_Unpickler(pickle.Unpickler):\n",
    "        def find_class(self, module, name):\n",
    "            if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "                return lambda b: torch.load(io.BytesIO(b))\n",
    "            return super().find_class(module, name)\n",
    "    \n",
    "    def safe_save(obj, filename):\n",
    "        \"\"\"Safely save torch objects with pickle\"\"\"\n",
    "        try:\n",
    "            # First try normal torch.save with legacy format\n",
    "            torch.save(obj, filename, pickle_protocol=4, _use_new_zipfile_serialization=False)\n",
    "            print(f\"✅ Successfully saved {filename}\")\n",
    "            return True\n",
    "        except Exception as e1:\n",
    "            try:\n",
    "                # Try with older protocol\n",
    "                torch.save(obj, filename, pickle_protocol=2, _use_new_zipfile_serialization=False)\n",
    "                print(f\"✅ Successfully saved {filename} (protocol 2)\")\n",
    "                return True\n",
    "            except Exception as e2:\n",
    "                print(f\"   ⚠️ Failed to save {filename}: {e2}\")\n",
    "                return False\n",
    "    \n",
    "    def test_save_methods(model, checkpoint, prefix=\"test\"):\n",
    "        \"\"\"Test different save methods\"\"\"\n",
    "        print(f\"\\n🧪 Testing save methods for {prefix}...\")\n",
    "        \n",
    "        # Method 1: Full checkpoint\n",
    "        if safe_save(checkpoint, f'{prefix}_full.pth'):\n",
    "            print(\"   ✅ Method 1: Full checkpoint - SUCCESS\")\n",
    "        \n",
    "        # Method 2: State dict only\n",
    "        try:\n",
    "            torch.save(model.state_dict(), f'{prefix}_state.pth', \n",
    "                     _use_new_zipfile_serialization=False)\n",
    "            print(\"   ✅ Method 2: State dict only - SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Method 2 failed: {e}\")\n",
    "        \n",
    "        # Method 3: CPU state dict\n",
    "        try:\n",
    "            cpu_model = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save(cpu_model, f'{prefix}_cpu.pth', \n",
    "                     _use_new_zipfile_serialization=False)\n",
    "            print(\"   ✅ Method 3: CPU state dict - SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Method 3 failed: {e}\")\n",
    "        \n",
    "        # Method 4: Numpy arrays\n",
    "        try:\n",
    "            numpy_weights = {}\n",
    "            for name, param in model.state_dict().items():\n",
    "                numpy_weights[name] = param.cpu().numpy()\n",
    "            with open(f'{prefix}_weights.pkl', 'wb') as f:\n",
    "                pickle.dump(numpy_weights, f)\n",
    "            print(\"   ✅ Method 4: Numpy arrays - SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Method 4 failed: {e}\")\n",
    "        \n",
    "        print(f\"\\n📋 Save test summary for {prefix}:\")\n",
    "        for method in ['full', 'state', 'cpu', 'weights']:\n",
    "            if os.path.exists(f'{prefix}_{method}.pth') or os.path.exists(f'{prefix}_weights.pkl'):\n",
    "                print(f\"   ✅ {method}: Saved\")\n",
    "            else:\n",
    "                print(f\"   ❌ {method}: Failed\")\n",
    "\n",
    "    # Test save methods before training\n",
    "    test_checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'config': config,\n",
    "        'training_history': training_history,\n",
    "        'epoch': 0\n",
    "    }\n",
    "    test_save_methods(model, test_checkpoint, \"before_training\")\n",
    "\n",
    "    for epoch in range(config['training_params']['n_epochs']):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        train_losses = train_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "        # Validation\n",
    "        val_loss = validate_epoch(model, val_loader, device)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "\n",
    "        # Record metrics\n",
    "        epoch_time = time.time() - start_time\n",
    "        training_history['train_loss'].append(train_losses['total_loss'])\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "        training_history['epoch_time'].append(epoch_time)\n",
    "\n",
    "        # GPU memory usage\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "            training_history['gpu_memory'].append(gpu_memory)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"\\n📊 Epoch {epoch+1}/{config['training_params']['n_epochs']}\")\n",
    "        print(f\"   Train Loss: {train_losses['total_loss']:.4f} (Action: {train_losses['action_loss']:.4f})\")\n",
    "        print(f\"   Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"   Time: {epoch_time:.1f}s\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'config': config,\n",
    "                'training_history': training_history,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            \n",
    "            print(\"   💾 Saving best model...\")\n",
    "            saved = safe_save(checkpoint, 'enhanced_transformer_best.pth')\n",
    "            \n",
    "            # Test all save methods\n",
    "            test_save_methods(model, checkpoint, f\"epoch_{epoch+1}_best\")\n",
    "\n",
    "    # Save final model\n",
    "    print(\"\\n💾 Saving final model...\")\n",
    "    final_checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': config,\n",
    "        'training_history': training_history\n",
    "    }\n",
    "    \n",
    "    safe_save(final_checkpoint, 'enhanced_transformer_final.pth')\n",
    "    test_save_methods(model, final_checkpoint, \"final\")\n",
    "\n",
    "    print(\"\\n✅ Training completed!\")\n",
    "    print(f\"🏆 Best validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # List all saved files\n",
    "    print(\"\\n📋 Saved files:\")\n",
    "    for f in os.listdir('.'):\n",
    "        if 'enhanced_transformer' in f or f.endswith('.pth') or f.endswith('.pkl'):\n",
    "            if os.path.getsize(f) > 0:\n",
    "                print(f\"   ✅ {f}: {os.path.getsize(f) / 1024 / 1024:.1f} MB\")\n",
    "            else:\n",
    "                print(f\"   ❌ {f}: Empty file\")\n",
    "\n",
    "    return training_history\n",
    "\n",
    "# Start training\n",
    "if 'train_loader' in locals() and 'val_loader' in locals() and 'optimizer' in locals():\n",
    "    training_history = start_training(model, train_loader, val_loader, optimizer, scheduler, config, device)\n",
    "else:\n",
    "    print(\"⚠️ Training setup not available. Please run all cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Test Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading saved models\n",
    "def test_model_loading():\n",
    "    \"\"\"Test loading models with different methods\"\"\"\n",
    "    print(\"🧪 Testing model loading...\")\n",
    "    \n",
    "    # Test files to load\n",
    "    test_files = [\n",
    "        'enhanced_transformer_best.pth',\n",
    "        'enhanced_transformer_final.pth',\n",
    "        'final_full.pth',\n",
    "        'final_cpu.pth',\n",
    "        'final_state.pth'\n",
    "    ]\n",
    "    \n",
    "    for file in test_files:\n",
    "        if os.path.exists(file):\n",
    "            print(f\"\\n📂 Testing {file}...\")\n",
    "            try:\n",
    "                checkpoint = torch.load(file, map_location=device)\n",
    "                print(f\"   ✅ Loaded successfully\")\n",
    "                print(f\"   📊 File size: {os.path.getsize(file) / 1024 / 1024:.1f} MB\")\n",
    "                \n",
    "                # Check what's in the checkpoint\n",
    "                if isinstance(checkpoint, dict):\n",
    "                    print(f\"   📋 Keys: {list(checkpoint.keys())}\")\n",
    "                    if 'model_state_dict' in checkpoint:\n",
    "                        print(f\"   🔧 Model parameters: {sum(p.numel() for p in checkpoint['model_state_dict'].values()):,}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Failed to load: {e}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ File not found: {file}\")\n",
    "\n",
    "# Run loading test\n",
    "if 'training_history' in locals():\n",
    "    test_model_loading()\n",
    "else:\n",
    "    print(\"⚠️ No training history available. Run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test summary\n",
    "def print_test_summary():\n",
    "    \"\"\"Print summary of test results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🧪 ENHANCED TRANSFORMER TRAINING TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Count saved files\n",
    "    saved_files = []\n",
    "    failed_methods = []\n",
    "    \n",
    "    for f in os.listdir('.'):\n",
    "        if 'enhanced_transformer' in f or f.endswith(('.pth', '.pkl')):\n",
    "            if os.path.getsize(f) > 0:\n",
    "                saved_files.append(f)\n",
    "            else:\n",
    "                failed_methods.append(f)\n",
    "    \n",
    "    print(f\"\\n📊 Results:\")\n",
    "    print(f\"   ✅ Successfully saved files: {len(saved_files)}\")\n",
    "    print(f\"   ❌ Failed/empty files: {len(failed_methods)}\")\n",
    "    \n",
    "    print(f\"\\n💾 Saved files:\")\n",
    "    for f in saved_files:\n",
    "        size_mb = os.path.getsize(f) / 1024 / 1024\n",
    "        print(f\"   - {f}: {size_mb:.1f} MB\")\n",
    "    \n",
    "    if failed_methods:\n",
    "        print(f\"\\n❌ Failed methods:\")\n",
    "        for f in failed_methods:\n",
    "            print(f\"   - {f}\")\n",
    "    \n",
    "    # Training results\n",
    "    if 'training_history' in locals() and training_history['train_loss']:\n",
    "        print(f\"\\n📈 Training results:\")\n",
    "        print(f\"   - Final train loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "        print(f\"   - Final val loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "        print(f\"   - Total epochs: {len(training_history['train_loss'])}\")\n",
    "        \n",
    "        # Best method recommendation\n",
    "        print(f\"\\n🎯 Recommendations for cloud training:\")\n",
    "        \n",
    "        if any('full.pth' in f for f in saved_files):\n",
    "            print(\"   ✅ Full checkpoint saving works - use this method\")\n",
    "        elif any('state.pth' in f for f in saved_files):\n",
    "            print(\"   ✅ State dict saving works - use this as backup\")\n",
    "        elif any('cpu.pth' in f for f in saved_files):\n",
    "            print(\"   ✅ CPU saving works - use this if GPU saving fails\")\n",
    "        elif any('weights.pkl' in f for f in saved_files):\n",
    "            print(\"   ✅ Numpy saving works - use this as last resort\")\n",
    "        else:\n",
    "            print(\"   ❌ All methods failed - need to investigate further\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Print summary\n",
    "print_test_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}