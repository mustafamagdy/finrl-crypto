{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Transformer Training for Cryptocurrency Trading\n",
    "\n",
    "**Phase 1 Implementation - GPU Accelerated Training**\n",
    "\n",
    "This notebook implements the enhanced transformer model with:\n",
    "- Extended sequence length (250 steps)\n",
    "- Temporal attention bias\n",
    "- Multi-scale processing\n",
    "- Advanced feature engineering\n",
    "- GPU acceleration support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All requirements installed successfully!\n",
      "🚀 Default device: cuda\n",
      "💻 GPU: NVIDIA GeForce RTX 4070\n",
      "🧠 GPU Memory: 12.5 GB\n",
      "\n",
      "🎯 Ready for enhanced transformer training!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install All Requirements for Enhanced Transformer Training\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"🚀 Installing Enhanced Transformer Requirements...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Update pip first\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install stable PyTorch version (2.1.0 is stable and doesn't have the API issues)\n",
    "print(\"🔥 Installing PyTorch with GPU support...\")\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install core ML libraries\n",
    "print(\"📊 Installing core ML libraries...\")\n",
    "!pip install numpy pandas scikit-learn matplotlib seaborn plotly\n",
    "\n",
    "# Install technical analysis libraries\n",
    "print(\"📈 Installing technical analysis libraries...\")\n",
    "!pip install ta talib-binary\n",
    "\n",
    "# Install utilities\n",
    "print(\"🔧 Installing utilities...\")\n",
    "!pip install tqdm psutil requests ipywidgets\n",
    "\n",
    "# Install Jupyter\n",
    "print(\"📓 Installing Jupyter...\")\n",
    "!pip install jupyter\n",
    "\n",
    "# Install stable-baselines3 for RL\n",
    "!pip install stable-baselines3\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"✅ All requirements installed successfully!\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"🚀 Default device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(f\"💻 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "  print(f\"🧠 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "elif torch.backends.mps.is_available():\n",
    "  print(\"🍎 Apple Silicon GPU available\")\n",
    "else:\n",
    "  print(\"⚠️ No GPU detected, using CPU\")\n",
    "\n",
    "print(\"\\n🎯 Ready for enhanced transformer training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using device: cuda\n",
      "🔧 PyTorch version: 2.8.0+cu128\n",
      "💻 GPU: NVIDIA GeForce RTX 4070\n",
      "🧠 GPU Memory: 12.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and handle PyTorch import issues\n",
    "import torch\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# Workaround for PyTorch import issues\n",
    "try:\n",
    "    from torch._utils_internal import justknobs_check\n",
    "except ImportError:\n",
    "    # Create a dummy function if the import fails\n",
    "    def justknobs_check(name, default=False):\n",
    "        return default\n",
    "\n",
    "# Fix for PyTorch 2.2+ pytree API changes\n",
    "try:\n",
    "    # Check if register_pytree_node exists\n",
    "    from torch.utils._pytree import register_pytree_node\n",
    "except ImportError:\n",
    "    # Apply monkey patch for older pytree API\n",
    "    import torch.utils._pytree as pytree\n",
    "    if not hasattr(pytree, 'register_pytree_node'):\n",
    "        def register_pytree_node(*args, **kwargs):\n",
    "            # Dummy implementation for compatibility\n",
    "            pass\n",
    "        pytree.register_pytree_node = register_pytree_node\n",
    "\n",
    "# Disable torch.compile to avoid more issues\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "print(f\"🔧 PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"💻 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"🧠 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: ta in /opt/conda/lib/python3.10/site-packages (0.11.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement talib-binary (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for talib-binary\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.0+cu121)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.10/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.10/site-packages (from triton==3.4.0->torch) (68.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.6 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Installing collected packages: triton, torch\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.4.0\n",
      "\u001b[2K    Uninstalling triton-3.4.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.4.0\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0\u001b[0m \u001b[32m0/2\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling torch-2.8.0:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]32m1/2\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 2.7.0 requires torch<3.0,>=2.3, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.0+cu121 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m✅ Packages installed successfully\n",
      "PyTorch version: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "# Install required packages with specific PyTorch version\n",
    "!pip install pandas numpy scikit-learn matplotlib ta talib-binary\n",
    "\n",
    "# Install stable PyTorch version\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "print(\"✅ Packages installed successfully\")\n",
    "\n",
    "# Verify PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1cOc9wKmdHxL4sKBZVWhSoAKdMVLE32lj\n",
      "To: /mnt/crypto_5min_2years.csv\n",
      "100%|██████████| 42.7M/42.7M [00:05<00:00, 8.14MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: crypto_5min_2years.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip -q install gdown\n",
    "\n",
    "import gdown\n",
    "\n",
    "# Your shared link\n",
    "url = \"https://drive.google.com/file/d/1cOc9wKmdHxL4sKBZVWhSoAKdMVLE32lj/view?usp=sharing\"\n",
    "\n",
    "# Where to save locally\n",
    "out_path = \"crypto_5min_2years.csv\"  # add .zip/.csv/etc if you know the type\n",
    "\n",
    "gdown.download(url, out_path, fuzzy=True)  # fuzzy=True lets you pass 'view' URLs\n",
    "print(\"Saved to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading data from crypto_5min_2years.csv...\n",
      "✅ Raw data shape: (630721, 7)\n",
      "📅 Date range: 2023-09-10 12:15:00 to 2025-09-09 12:15:00\n",
      "💰 Symbols: Unknown\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:15:00</th>\n",
       "      <td>BNBUSDT</td>\n",
       "      <td>213.10</td>\n",
       "      <td>213.10</td>\n",
       "      <td>212.90</td>\n",
       "      <td>213.00</td>\n",
       "      <td>385.15700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:15:00</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>25815.18</td>\n",
       "      <td>25815.19</td>\n",
       "      <td>25801.86</td>\n",
       "      <td>25803.16</td>\n",
       "      <td>25.21043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:15:00</th>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1625.90</td>\n",
       "      <td>1625.91</td>\n",
       "      <td>1624.86</td>\n",
       "      <td>1624.86</td>\n",
       "      <td>239.22490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:20:00</th>\n",
       "      <td>BNBUSDT</td>\n",
       "      <td>213.00</td>\n",
       "      <td>213.10</td>\n",
       "      <td>212.90</td>\n",
       "      <td>213.10</td>\n",
       "      <td>375.34700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:20:00</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>25803.17</td>\n",
       "      <td>25816.67</td>\n",
       "      <td>25803.16</td>\n",
       "      <td>25812.27</td>\n",
       "      <td>18.98413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tic      open      high       low     close  \\\n",
       "date                                                                   \n",
       "2023-09-10 12:15:00  BNBUSDT    213.10    213.10    212.90    213.00   \n",
       "2023-09-10 12:15:00  BTCUSDT  25815.18  25815.19  25801.86  25803.16   \n",
       "2023-09-10 12:15:00  ETHUSDT   1625.90   1625.91   1624.86   1624.86   \n",
       "2023-09-10 12:20:00  BNBUSDT    213.00    213.10    212.90    213.10   \n",
       "2023-09-10 12:20:00  BTCUSDT  25803.17  25816.67  25803.16  25812.27   \n",
       "\n",
       "                        volume  \n",
       "date                            \n",
       "2023-09-10 12:15:00  385.15700  \n",
       "2023-09-10 12:15:00   25.21043  \n",
       "2023-09-10 12:15:00  239.22490  \n",
       "2023-09-10 12:20:00  375.34700  \n",
       "2023-09-10 12:20:00   18.98413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 630721 entries, 2023-09-10 12:15:00 to 2025-09-09 12:15:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   tic     630721 non-null  object \n",
      " 1   open    630721 non-null  float64\n",
      " 2   high    630721 non-null  float64\n",
      " 3   low     630721 non-null  float64\n",
      " 4   close   630721 non-null  float64\n",
      " 5   volume  630721 non-null  float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 33.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load cryptocurrency data\n",
    "def load_crypto_data(csv_path='crypto_5min_2years.csv'):\n",
    "    \"\"\"Load and preprocess cryptocurrency data\"\"\"\n",
    "    print(f\"📊 Loading data from {csv_path}...\")\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"❌ File {csv_path} not found!\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"✅ Raw data shape: {df.shape}\")\n",
    "    \n",
    "    # Handle datetime index\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.set_index('date', inplace=True)\n",
    "    elif 'timestamp' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['timestamp'])\n",
    "        df.set_index('date', inplace=True)\n",
    "    else:\n",
    "        # Create datetime index for sample data\n",
    "        if len(df) > 0:\n",
    "            dates = pd.date_range(start='2024-01-01', periods=len(df), freq='5T')\n",
    "            df.index = dates\n",
    "    \n",
    "    print(f\"📅 Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"💰 Symbols: {df['symbol'].unique() if 'symbol' in df.columns else 'Unknown'}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "df = load_crypto_data()\n",
    "\n",
    "if df is not None:\n",
    "    display(df.head())\n",
    "    print(f\"\\n📋 Data info:\")\n",
    "    display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Enhanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ TA-Lib not available, using manual calculations\n",
      "🔧 Calculating enhanced features...\n",
      "🔧 Calculating enhanced trading features...\n",
      "  📊 Calculating core technical indicators...\n",
      "  💰 Calculating order flow indicators...\n",
      "  🏛️ Calculating market microstructure features...\n",
      "  📈 Calculating volatility features...\n",
      "  🚀 Calculating momentum and trend features...\n",
      "  📊 Calculating support and resistance levels...\n",
      "  💹 Calculating price-based features...\n",
      "  📦 Calculating volume-based features...\n",
      "  ⏰ Calculating time-based features...\n",
      "  ⏪ Calculating lagged features...\n",
      "✅ Enhanced features calculated: 66 features\n",
      "✅ Enhanced features shape: (630721, 66)\n",
      "🎯 Selecting important features...\n",
      "✅ Selected 29 important features\n",
      "🎯 Selected features shape: (630721, 29)\n",
      "✅ Final processed features shape: (630721, 29)\n",
      "📋 Feature columns: ['open', 'volume', 'rsi', 'rsi_7', 'macd', 'macd_signal', 'bb_upper', 'stoch_k', 'stoch_d', 'vwap']...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>rsi_7</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>stoch_k</th>\n",
       "      <th>stoch_d</th>\n",
       "      <th>vwap</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_session_open</th>\n",
       "      <th>close_lag_1</th>\n",
       "      <th>volume_lag_1</th>\n",
       "      <th>volume_lag_2</th>\n",
       "      <th>volume_lag_3</th>\n",
       "      <th>volume_lag_5</th>\n",
       "      <th>volume_lag_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:15:00</th>\n",
       "      <td>213.10</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>55.555415</td>\n",
       "      <td>50.000098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34033.495843</td>\n",
       "      <td>99.954147</td>\n",
       "      <td>35.158169</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934545</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>213.00</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.157</td>\n",
       "      <td>385.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:15:00</th>\n",
       "      <td>25815.18</td>\n",
       "      <td>25.21043</td>\n",
       "      <td>55.555415</td>\n",
       "      <td>50.000098</td>\n",
       "      <td>574.138205</td>\n",
       "      <td>318.965670</td>\n",
       "      <td>34033.495843</td>\n",
       "      <td>99.954147</td>\n",
       "      <td>35.158169</td>\n",
       "      <td>1785.320461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934545</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>213.00</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.157</td>\n",
       "      <td>385.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:15:00</th>\n",
       "      <td>1625.90</td>\n",
       "      <td>239.22490</td>\n",
       "      <td>55.555415</td>\n",
       "      <td>50.000098</td>\n",
       "      <td>-18.201604</td>\n",
       "      <td>180.782361</td>\n",
       "      <td>34033.495843</td>\n",
       "      <td>99.954147</td>\n",
       "      <td>35.158169</td>\n",
       "      <td>1726.356697</td>\n",
       "      <td>...</td>\n",
       "      <td>8.489124</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>25803.16</td>\n",
       "      <td>25.21043</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.157</td>\n",
       "      <td>385.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:20:00</th>\n",
       "      <td>213.00</td>\n",
       "      <td>375.34700</td>\n",
       "      <td>55.555415</td>\n",
       "      <td>50.000098</td>\n",
       "      <td>-338.134343</td>\n",
       "      <td>4.997569</td>\n",
       "      <td>34033.495843</td>\n",
       "      <td>99.954147</td>\n",
       "      <td>35.158169</td>\n",
       "      <td>1172.156689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569013</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1624.86</td>\n",
       "      <td>239.22490</td>\n",
       "      <td>25.21043</td>\n",
       "      <td>385.15700</td>\n",
       "      <td>385.157</td>\n",
       "      <td>385.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10 12:20:00</th>\n",
       "      <td>25803.17</td>\n",
       "      <td>18.98413</td>\n",
       "      <td>55.555415</td>\n",
       "      <td>50.000098</td>\n",
       "      <td>513.787460</td>\n",
       "      <td>156.351059</td>\n",
       "      <td>34033.495843</td>\n",
       "      <td>99.954147</td>\n",
       "      <td>35.158169</td>\n",
       "      <td>1620.217612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949422</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>213.10</td>\n",
       "      <td>375.34700</td>\n",
       "      <td>239.22490</td>\n",
       "      <td>25.21043</td>\n",
       "      <td>385.157</td>\n",
       "      <td>385.157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     volume        rsi      rsi_7        macd  \\\n",
       "date                                                                         \n",
       "2023-09-10 12:15:00    213.10  385.15700  55.555415  50.000098    0.000000   \n",
       "2023-09-10 12:15:00  25815.18   25.21043  55.555415  50.000098  574.138205   \n",
       "2023-09-10 12:15:00   1625.90  239.22490  55.555415  50.000098  -18.201604   \n",
       "2023-09-10 12:20:00    213.00  375.34700  55.555415  50.000098 -338.134343   \n",
       "2023-09-10 12:20:00  25803.17   18.98413  55.555415  50.000098  513.787460   \n",
       "\n",
       "                     macd_signal      bb_upper    stoch_k    stoch_d  \\\n",
       "date                                                                   \n",
       "2023-09-10 12:15:00     0.000000  34033.495843  99.954147  35.158169   \n",
       "2023-09-10 12:15:00   318.965670  34033.495843  99.954147  35.158169   \n",
       "2023-09-10 12:15:00   180.782361  34033.495843  99.954147  35.158169   \n",
       "2023-09-10 12:20:00     4.997569  34033.495843  99.954147  35.158169   \n",
       "2023-09-10 12:20:00   156.351059  34033.495843  99.954147  35.158169   \n",
       "\n",
       "                            vwap  ...  volume_change  hour  day_of_week  \\\n",
       "date                              ...                                     \n",
       "2023-09-10 12:15:00   213.000000  ...      -0.934545    12            6   \n",
       "2023-09-10 12:15:00  1785.320461  ...      -0.934545    12            6   \n",
       "2023-09-10 12:15:00  1726.356697  ...       8.489124    12            6   \n",
       "2023-09-10 12:20:00  1172.156689  ...       0.569013    12            6   \n",
       "2023-09-10 12:20:00  1620.217612  ...      -0.949422    12            6   \n",
       "\n",
       "                     is_session_open  close_lag_1  volume_lag_1  volume_lag_2  \\\n",
       "date                                                                            \n",
       "2023-09-10 12:15:00                1       213.00     385.15700     385.15700   \n",
       "2023-09-10 12:15:00                1       213.00     385.15700     385.15700   \n",
       "2023-09-10 12:15:00                1     25803.16      25.21043     385.15700   \n",
       "2023-09-10 12:20:00                1      1624.86     239.22490      25.21043   \n",
       "2023-09-10 12:20:00                1       213.10     375.34700     239.22490   \n",
       "\n",
       "                     volume_lag_3  volume_lag_5  volume_lag_10  \n",
       "date                                                            \n",
       "2023-09-10 12:15:00     385.15700       385.157        385.157  \n",
       "2023-09-10 12:15:00     385.15700       385.157        385.157  \n",
       "2023-09-10 12:15:00     385.15700       385.157        385.157  \n",
       "2023-09-10 12:20:00     385.15700       385.157        385.157  \n",
       "2023-09-10 12:20:00      25.21043       385.157        385.157  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import enhanced features module\n",
    "from enhanced_features import calculate_enhanced_features, select_important_features\n",
    "\n",
    "# Calculate enhanced features\n",
    "def process_features(df):\n",
    "    \"\"\"Process and enhance features for training\"\"\"\n",
    "    print(\"🔧 Calculating enhanced features...\")\n",
    "    \n",
    "    # Calculate enhanced features\n",
    "    enhanced_df = calculate_enhanced_features(df)\n",
    "    print(f\"✅ Enhanced features shape: {enhanced_df.shape}\")\n",
    "    \n",
    "    # Select important features\n",
    "    selected_features = select_important_features(enhanced_df, n_features=40)\n",
    "    print(f\"🎯 Selected features shape: {selected_features.shape}\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    selected_features = selected_features.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "    \n",
    "    print(f\"✅ Final processed features shape: {selected_features.shape}\")\n",
    "    print(f\"📋 Feature columns: {list(selected_features.columns[:10])}...\")\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Process features\n",
    "if df is not None:\n",
    "    features_df = process_features(df)\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Enhanced Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Model configuration:\n",
      "   model_params: {'d_model': 512, 'n_heads': 16, 'n_layers': 8, 'd_ff': 2048, 'dropout': 0.15, 'max_seq_len': 250, 'use_multi_scale': True, 'scales': [5, 15, 30, 60]}\n",
      "   training_params: {'learning_rate': 5e-05, 'batch_size': 32, 'n_epochs': 150, 'warmup_steps': 2000, 'weight_decay': 1e-05, 'gradient_clipping': 1.0}\n",
      "   environment_params: {'initial_amount': 100000, 'transaction_cost_pct': 0.001, 'sequence_length': 250, 'use_multi_scale': True}\n",
      "\n",
      "🧠 Model created successfully!\n",
      "📊 Input dimension: 29\n",
      "🔧 Model parameters: 27,374,350\n",
      "💾 Model size: 104.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Import enhanced transformer\n",
    "from transformer_enhanced_v2 import EnhancedCryptoTransformer, create_enhanced_transformer_config\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create model configuration\n",
    "config = create_enhanced_transformer_config()\n",
    "print(\"📋 Model configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Create model\n",
    "if 'features_df' in locals():\n",
    "    input_dim = features_df.shape[1]\n",
    "    model = EnhancedCryptoTransformer(\n",
    "        input_dim=input_dim,\n",
    "        **config['model_params']\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\n🧠 Model created successfully!\")\n",
    "    print(f\"📊 Input dimension: {input_dim}\")\n",
    "    print(f\"🔧 Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"💾 Model size: {sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(\"⚠️ Features not available, creating test model\")\n",
    "    model = EnhancedCryptoTransformer(\n",
    "        input_dim=25,\n",
    "        **config['model_params']\n",
    "    ).to(device)\n",
    "    print(f\"🧠 Test model created with 25 input dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing model forward pass...\n",
      "✅ Model forward pass successful!\n",
      "📊 Output shapes:\n",
      "   action: torch.Size([4, 1])\n",
      "   market_regime: torch.Size([4, 4])\n",
      "   confidence: torch.Size([4, 1])\n",
      "   volatility: torch.Size([4, 1])\n",
      "   risk_assessment: torch.Size([4, 3])\n",
      "   hidden_state: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "# Test model forward pass\n",
    "def test_model(model, input_dim=25):\n",
    "    \"\"\"Test model forward pass\"\"\"\n",
    "    print(\"🧪 Testing model forward pass...\")\n",
    "    \n",
    "    # Create test input\n",
    "    batch_size = 4\n",
    "    seq_len = config['model_params']['max_seq_len']\n",
    "    test_input = torch.randn(batch_size, seq_len, input_dim).to(device)\n",
    "    \n",
    "    # Create multi-scale inputs\n",
    "    scale_inputs = {\n",
    "        5: torch.randn(batch_size, seq_len, input_dim).to(device),\n",
    "        15: torch.randn(batch_size, seq_len//3, input_dim).to(device),\n",
    "        30: torch.randn(batch_size, seq_len//6, input_dim).to(device),\n",
    "    }\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_input, scale_inputs)\n",
    "    \n",
    "    print(\"✅ Model forward pass successful!\")\n",
    "    print(\"📊 Output shapes:\")\n",
    "    for key, value in outputs.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"   {key}: {value.shape}\")\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Test model\n",
    "test_outputs = test_model(model, input_dim if 'features_df' in locals() else 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏋️‍♂️ Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Creating datasets...\n",
      "📊 Training samples: 504372\n",
      "📊 Validation samples: 126094\n",
      "🔧 Batch size: 32\n",
      "🔧 Training batches: 15762\n",
      "🔧 Validation batches: 3941\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "class CryptoDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for cryptocurrency trading\"\"\"\n",
    "    def __init__(self, features_df, sequence_length=250, prediction_horizon=5):\n",
    "        self.features = features_df.values\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.close_prices = features_df['close'].values if 'close' in features_df.columns else self.features[:, 0]\n",
    "        \n",
    "        self.sequences, self.targets = self._prepare_sequences()\n",
    "    \n",
    "    def _prepare_sequences(self):\n",
    "        \"\"\"Prepare training sequences\"\"\"\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        \n",
    "        for i in range(len(self.features) - self.sequence_length - self.prediction_horizon):\n",
    "            # Input sequence\n",
    "            seq = self.features[i:i + self.sequence_length]\n",
    "            sequences.append(seq)\n",
    "            \n",
    "            # Target (future return)\n",
    "            current_price = self.close_prices[i + self.sequence_length - 1]\n",
    "            future_price = self.close_prices[i + self.sequence_length + self.prediction_horizon - 1]\n",
    "            target_return = (future_price - current_price) / current_price\n",
    "            targets.append(target_return)\n",
    "        \n",
    "        return np.array(sequences), np.array(targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = torch.FloatTensor(self.sequences[idx])\n",
    "        target = torch.FloatTensor([self.targets[idx]])\n",
    "        return sequence, target\n",
    "\n",
    "# Create datasets\n",
    "if 'features_df' in locals():\n",
    "    print(\"🔧 Creating datasets...\")\n",
    "    \n",
    "    # Create dataset\n",
    "    full_dataset = CryptoDataset(features_df, sequence_length=config['model_params']['max_seq_len'])\n",
    "    \n",
    "    # Split data\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Training samples: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    batch_size = config['training_params']['batch_size']\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    print(f\"🔧 Batch size: {batch_size}\")\n",
    "    print(f\"🔧 Training batches: {len(train_loader)}\")\n",
    "    print(f\"🔧 Validation batches: {len(val_loader)}\")\n",
    "else:\n",
    "    print(\"⚠️ Features not available, skipping dataset creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training setup completed!\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Suppress PyTorch warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Initialize training components\n",
    "try:\n",
    "    if 'train_loader' in locals():\n",
    "        # Optimizer and scheduler\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config['training_params']['learning_rate'],\n",
    "            weight_decay=config['training_params']['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=config['training_params']['n_epochs'],\n",
    "            eta_min=config['training_params']['learning_rate'] * 0.1\n",
    "        )\n",
    "        \n",
    "        # Loss functions\n",
    "        action_loss_fn = nn.MSELoss()\n",
    "        confidence_loss_fn = nn.MSELoss()\n",
    "        \n",
    "        # Training history\n",
    "        training_history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'learning_rate': [],\n",
    "            'epoch_time': [],\n",
    "            'gpu_memory': []\n",
    "        }\n",
    "        \n",
    "        print(\"🚀 Training setup completed!\")\n",
    "    else:\n",
    "        print(\"⚠️ Training setup skipped - no datasets available\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error setting up training: {str(e)}\")\n",
    "    print(\"This might be due to PyTorch compatibility issues. Please restart the kernel and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    action_loss = 0\n",
    "    confidence_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences = sequences.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        \n",
    "        # Calculate losses\n",
    "        action_loss_batch = action_loss_fn(outputs['action'], targets)\n",
    "        confidence_loss_batch = confidence_loss_fn(outputs['confidence'], torch.ones_like(outputs['confidence']) * 0.8)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss_batch = action_loss_batch + 0.2 * confidence_loss_batch\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss_batch.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses\n",
    "        total_loss += total_loss_batch.item()\n",
    "        action_loss += action_loss_batch.item()\n",
    "        confidence_loss += confidence_loss_batch.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(train_loader)}: Loss = {total_loss_batch.item():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_loss': total_loss / num_batches,\n",
    "        'action_loss': action_loss / num_batches,\n",
    "        'confidence_loss': confidence_loss / num_batches\n",
    "    }\n",
    "\n",
    "def validate_epoch(model, val_loader, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in val_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(sequences)\n",
    "            \n",
    "            loss = action_loss_fn(outputs['action'], targets)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "print(\"🔧 Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# Start training\ndef start_training(model, train_loader, val_loader, optimizer, scheduler, config, device):\n    \"\"\"Start the training process\"\"\"\n    print(\"🚀 Starting enhanced transformer training...\")\n    print(f\"📊 Training samples: {len(train_loader.dataset)}\")\n    print(f\"📊 Validation samples: {len(val_loader.dataset)}\")\n    print(f\"🧠 Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    print(f\"🔧 Epochs: {config['training_params']['n_epochs']}\")\n\n    best_val_loss = float('inf')\n    training_history = {\n        'train_loss': [],\n        'val_loss': [],\n        'learning_rate': [],\n        'epoch_time': [],\n        'gpu_memory': []\n    }\n\n    # Fix PyTorch serialization issues\n    import pickle\n    import io\n    \n    class CPU_Unpickler(pickle.Unpickler):\n        def find_class(self, module, name):\n            if module == 'torch.storage' and name == '_load_from_bytes':\n                return lambda b: torch.load(io.BytesIO(b))\n            return super().find_class(module, name)\n    \n    def safe_save(obj, filename):\n        \"\"\"Safely save torch objects with pickle\"\"\"\n        try:\n            # First try normal torch.save with legacy format\n            torch.save(obj, filename, pickle_protocol=4, _use_new_zipfile_serialization=False)\n            return True\n        except Exception as e1:\n            try:\n                # Try with older protocol\n                torch.save(obj, filename, pickle_protocol=2, _use_new_zipfile_serialization=False)\n                return True\n            except Exception as e2:\n                print(f\"   ⚠️ Failed to save {filename}: {e2}\")\n                return False\n\n    for epoch in range(config['training_params']['n_epochs']):\n        start_time = time.time()\n\n        # Training\n        train_losses = train_epoch(model, train_loader, optimizer, device)\n\n        # Validation\n        val_loss = validate_epoch(model, val_loader, device)\n\n        # Learning rate scheduling\n        scheduler.step()\n\n        # Record metrics\n        epoch_time = time.time() - start_time\n        training_history['train_loss'].append(train_losses['total_loss'])\n        training_history['val_loss'].append(val_loss)\n        training_history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n        training_history['epoch_time'].append(epoch_time)\n\n        # GPU memory usage\n        if torch.cuda.is_available():\n            gpu_memory = torch.cuda.memory_allocated() / 1024**3\n            training_history['gpu_memory'].append(gpu_memory)\n\n        # Print progress\n        if (epoch + 1) % 10 == 0:\n            print(f\"\\n📊 Epoch {epoch+1}/{config['training_params']['n_epochs']}\")\n            print(f\"   Train Loss: {train_losses['total_loss']:.4f} (Action: {train_losses['action_loss']:.4f})\")\n            print(f\"   Val Loss: {val_loss:.4f}\")\n            print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n            print(f\"   Time: {epoch_time:.1f}s\")\n            if torch.cuda.is_available():\n                print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n\n        # Save best model (with robust error handling)\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            checkpoint = {\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'config': config,\n                'training_history': training_history,\n                'epoch': epoch\n            }\n            \n            # Try to save using multiple methods\n            print(\"   💾 Attempting to save best model...\")\n            saved = False\n            \n            # Method 1: Safe save with pickle\n            if not saved:\n                saved = safe_save(checkpoint, 'enhanced_transformer_best.pth')\n            \n            # Method 2: Save only state dict if full checkpoint fails\n            if not saved:\n                try:\n                    torch.save(model.state_dict(), 'enhanced_transformer_best_state.pth', \n                             _use_new_zipfile_serialization=False)\n                    print(\"   💾 Saved model state dict only\")\n                    saved = True\n                except Exception as e:\n                    print(f\"   ⚠️ Failed to save state dict: {e}\")\n            \n            # Method 3: CPU transfer then save\n            if not saved:\n                try:\n                    model_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n                    torch.save(model_cpu, 'enhanced_transformer_best_cpu.pth', \n                             _use_new_zipfile_serialization=False)\n                    print(\"   💾 Saved model in CPU mode\")\n                    saved = True\n                except Exception as e:\n                    print(f\"   ⚠️ Failed to save CPU model: {e}\")\n\n    # Save final model (with same robust handling)\n    print(\"   💾 Attempting to save final model...\")\n    saved = False\n    \n    final_checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'config': config,\n        'training_history': training_history\n    }\n    \n    # Try all save methods\n    if not saved:\n        saved = safe_save(final_checkpoint, 'enhanced_transformer_final.pth')\n    \n    if not saved:\n        try:\n            torch.save(model.state_dict(), 'enhanced_transformer_final_state.pth', \n                     _use_new_zipfile_serialization=False)\n            print(\"   💾 Saved final model state dict\")\n            saved = True\n        except Exception as e:\n            print(f\"   ⚠️ Failed to save final state dict: {e}\")\n\n    print(\"\\n✅ Training completed!\")\n    print(f\"🏆 Best validation loss: {best_val_loss:.4f}\")\n\n    return training_history\n\n# Uncomment to start training\nif 'train_loader' in locals() and 'val_loader' in locals() and 'optimizer' in locals():\n    training_history = start_training(model, train_loader, val_loader, optimizer, scheduler, config, device)\nelse:\n    print(\"⚠️ Training setup not available. Please run all cells above first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Emergency model save (if training completes but save fails)\ndef emergency_save_model(model, config=None, training_history=None):\n    \"\"\"Emergency save function if normal saving fails\"\"\"\n    print(\"🚨 Emergency save initiated...\")\n    \n    try:\n        # Method 1: Save state dict only\n        torch.save(model.state_dict(), 'emergency_model_state.pth', \n                 _use_new_zipfile_serialization=False)\n        print(\"✅ Saved model state dict to emergency_model_state.pth\")\n    except Exception as e:\n        print(f\"❌ Failed to save state dict: {e}\")\n    \n    try:\n        # Method 2: CPU conversion\n        cpu_model = {k: v.cpu() for k, v in model.state_dict().items()}\n        torch.save(cpu_model, 'emergency_model_cpu.pth', \n                 _use_new_zipfile_serialization=False)\n        print(\"✅ Saved CPU model to emergency_model_cpu.pth\")\n    except Exception as e:\n        print(f\"❌ Failed to save CPU model: {e}\")\n    \n    try:\n        # Method 3: Save as numpy arrays\n        numpy_weights = {}\n        for name, param in model.state_dict().items():\n            numpy_weights[name] = param.cpu().numpy()\n        \n        import pickle\n        with open('emergency_model_weights.pkl', 'wb') as f:\n            pickle.dump(numpy_weights, f)\n        print(\"✅ Saved weights as numpy arrays to emergency_model_weights.pkl\")\n    except Exception as e:\n        print(f\"❌ Failed to save numpy weights: {e}\")\n\n# Run emergency save if needed\nif 'model' in locals():\n    emergency_save_model(model, config, training_history if 'training_history' in locals() else None)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "def plot_training_results(history):\n",
    "    \"\"\"Plot training results\"\"\"\n",
    "    if not history or not history['train_loss']:\n",
    "        print(\"⚠️ No training history available\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', color='red')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[0, 1].plot(history['learning_rate'], color='green')\n",
    "    axes[0, 1].set_title('Learning Rate Schedule')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Learning Rate')\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Epoch time plot\n",
    "    axes[1, 0].plot(history['epoch_time'], color='orange')\n",
    "    axes[1, 0].set_title('Training Time per Epoch')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Time (seconds)')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # GPU memory plot\n",
    "    if history['gpu_memory']:\n",
    "        axes[1, 1].plot(history['gpu_memory'], color='purple')\n",
    "        axes[1, 1].set_title('GPU Memory Usage')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Memory (GB)')\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"📊 Training results plotted and saved!\")\n",
    "\n",
    "# Plot results if training history exists\n",
    "if 'training_history' in locals() and training_history['train_loss']:\n",
    "    plot_training_results(training_history)\n",
    "else:\n",
    "    print(\"⚠️ No training history to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in val_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(sequences)\n",
    "            \n",
    "            predictions.extend(outputs['action'].cpu().numpy())\n",
    "            actuals.extend(targets.cpu().numpy())\n",
    "            confidences.extend(outputs['confidence'].cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    confidences = np.array(confidences)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = np.mean((predictions - actuals) ** 2)\n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    r2 = 1 - np.sum((actuals - predictions) ** 2) / np.sum((actuals - np.mean(actuals)) ** 2)\n",
    "    \n",
    "    # Direction accuracy\n",
    "    pred_direction = np.sign(predictions)\n",
    "    actual_direction = np.sign(actuals)\n",
    "    direction_accuracy = np.mean(pred_direction == actual_direction)\n",
    "    \n",
    "    print(\"📊 Model Evaluation Results:\")\n",
    "    print(f\"   MSE: {mse:.6f}\")\n",
    "    print(f\"   MAE: {mae:.6f}\")\n",
    "    print(f\"   R²: {r2:.6f}\")\n",
    "    print(f\"   Direction Accuracy: {direction_accuracy:.2%}\")\n",
    "    print(f\"   Average Confidence: {np.mean(confidences):.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'direction_accuracy': direction_accuracy,\n",
    "        'confidence': np.mean(confidences)\n",
    "    }\n",
    "\n",
    "# Evaluate model if available\n",
    "if 'val_loader' in locals():\n",
    "    evaluation_results = evaluate_model(model, val_loader, device)\n",
    "else:\n",
    "    print(\"⚠️ Model not available for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Model Loading and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "def load_trained_model(model_path='enhanced_transformer_best.pth'):\n",
    "    \"\"\"Load a trained model\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"❌ Model file {model_path} not found\")\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Recreate model architecture\n",
    "    if 'features_df' in locals():\n",
    "        input_dim = features_df.shape[1]\n",
    "    else:\n",
    "        input_dim = 25  # Default\n",
    "    \n",
    "    loaded_model = EnhancedCryptoTransformer(\n",
    "        input_dim=input_dim,\n",
    "        **checkpoint['config']['model_params']\n",
    "    ).to(device)\n",
    "    \n",
    "    loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    loaded_model.eval()\n",
    "    \n",
    "    print(f\"✅ Model loaded from {model_path}\")\n",
    "    print(f\"📊 Model was trained for {checkpoint.get('epoch', 'unknown') + 1} epochs\")\n",
    "    \n",
    "    return loaded_model, checkpoint\n",
    "\n",
    "# Function for inference\n",
    "def predict_trading_signal(model, sequence_data, device):\n",
    "    \"\"\"Generate trading signal from sequence data\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Ensure correct shape\n",
    "        if len(sequence_data.shape) == 2:\n",
    "            sequence_data = sequence_data.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        sequence_data = sequence_data.to(device)\n",
    "        \n",
    "        outputs = model(sequence_data)\n",
    "        \n",
    "        action = outputs['action'].cpu().numpy()[0][0]\n",
    "        confidence = outputs['confidence'].cpu().numpy()[0][0]\n",
    "        market_regime = outputs['market_regime'].cpu().numpy()[0]\n",
    "        volatility = outputs['volatility'].cpu().numpy()[0][0]\n",
    "        risk_assessment = outputs['risk_assessment'].cpu().numpy()[0]\n",
    "        \n",
    "    # Interpret results\n",
    "    signal_strength = abs(action) * confidence\n",
    "    \n",
    "    if action > 0.1:\n",
    "        signal = \"BUY\"\n",
    "    elif action < -0.1:\n",
    "        signal = \"SELL\"\n",
    "    else:\n",
    "        signal = \"HOLD\"\n",
    "    \n",
    "    regime_labels = ['Bull', 'Bear', 'Ranging', 'Volatile']\n",
    "    regime = regime_labels[np.argmax(market_regime)]\n",
    "    \n",
    "    risk_labels = ['Low', 'Medium', 'High']\n",
    "    risk_level = risk_labels[np.argmax(risk_assessment)]\n",
    "    \n",
    "    return {\n",
    "        'signal': signal,\n",
    "        'action': action,\n",
    "        'confidence': confidence,\n",
    "        'signal_strength': signal_strength,\n",
    "        'market_regime': regime,\n",
    "        'volatility': volatility,\n",
    "        'risk_level': risk_level\n",
    "    }\n",
    "\n",
    "# Test loading model\n",
    "if os.path.exists('enhanced_transformer_best.pth'):\n",
    "    loaded_model, checkpoint = load_trained_model()\n",
    "    if loaded_model:\n",
    "        print(\"✅ Model loading test successful!\")\n",
    "else:\n",
    "    print(\"⚠️ No trained model found for loading test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎮 Interactive Trading Signal Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive trading signal generator\n",
    "def generate_trading_signals_demo(num_signals=5):\n",
    "    \"\"\"Generate demo trading signals\"\"\"\n",
    "    if 'loaded_model' not in locals() or loaded_model is None:\n",
    "        print(\"⚠️ No loaded model available for demo\")\n",
    "        return\n",
    "    \n",
    "    if 'features_df' not in locals():\n",
    "        print(\"⚠️ No features available for demo\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🎮 Generating {num_signals} trading signals...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Generate random sequences from the dataset\n",
    "    for i in range(num_signals):\n",
    "        # Get random sequence\n",
    "        start_idx = np.random.randint(0, len(features_df) - 250)\n",
    "        sequence_data = features_df.iloc[start_idx:start_idx + 250].values\n",
    "        \n",
    "        # Get current price\n",
    "        current_price = sequence_data[-1, features_df.columns.get_loc('close')] if 'close' in features_df.columns else sequence_data[-1, 0]\n",
    "        \n",
    "        # Generate prediction\n",
    "        prediction = predict_trading_signal(loaded_model, sequence_data, device)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n📊 Signal {i+1}:\")\n",
    "        print(f\"   Current Price: ${current_price:,.2f}\")\n",
    "        print(f\"   Signal: {prediction['signal']}\")\n",
    "        print(f\"   Action: {prediction['action']:.3f}\")\n",
    "        print(f\"   Confidence: {prediction['confidence']:.3f}\")\n",
    "        print(f\"   Signal Strength: {prediction['signal_strength']:.3f}\")\n",
    "        print(f\"   Market Regime: {prediction['market_regime']}\")\n",
    "        print(f\"   Volatility: {prediction['volatility']:.3f}\")\n",
    "        print(f\"   Risk Level: {prediction['risk_level']}\")\n",
    "        \n",
    "        # Trading recommendation\n",
    "        if prediction['signal_strength'] > 0.7:\n",
    "            print(f\"   🎯 Recommendation: STRONG {prediction['signal']}\")\n",
    "        elif prediction['signal_strength'] > 0.4:\n",
    "            print(f\"   🎯 Recommendation: MODERATE {prediction['signal']}\")\n",
    "        else:\n",
    "            print(f\"   🎯 Recommendation: WEAK {prediction['signal']} - Consider holding\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    print(\"\\n✅ Demo completed!\")\n",
    "\n",
    "# Run demo if model is available\n",
    "if 'loaded_model' in locals() and loaded_model is not None:\n",
    "    generate_trading_signals_demo(3)\n",
    "else:\n",
    "    print(\"⚠️ Demo not available - no trained model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 System Information and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display system information\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "def display_system_info():\n",
    "    \"\"\"Display system information\"\"\"\n",
    "    print(\"🖥️ System Information\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Python: {platform.python_version()}\")\n",
    "    print(f\"PyTorch: {torch.__version__}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # CPU info\n",
    "    print(f\"\\n💻 CPU Info:\")\n",
    "    print(f\"   Cores: {psutil.cpu_count(logical=True)}\")\n",
    "    print(f\"   Usage: {psutil.cpu_percent()}%\")\n",
    "    print(f\"   Memory: {psutil.virtual_memory().total / 1024**3:.1f} GB\")\n",
    "    print(f\"   Memory Available: {psutil.virtual_memory().available / 1024**3:.1f} GB\")\n",
    "    \n",
    "    # GPU info\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n🎮 GPU Info:\")\n",
    "        print(f\"   Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"   Allocated: {torch.cuda.memory_allocated() / 1024**3:.1f} GB\")\n",
    "        print(f\"   Cached: {torch.cuda.memory_reserved() / 1024**3:.1f} GB\")\n",
    "        print(f\"   Utilization: {torch.cuda.utilization()}%\")\n",
    "    \n",
    "    # Model info\n",
    "    if 'model' in locals():\n",
    "        print(f\"\\n🧠 Model Info:\")\n",
    "        print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        print(f\"   Trainable: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "        print(f\"   Size: {sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        # Parameter count by type\n",
    "        param_counts = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            param_type = name.split('.')[0]\n",
    "            param_counts[param_type] = param_counts.get(param_type, 0) + param.numel()\n",
    "        \n",
    "        print(f\"   Parameter breakdown:\")\n",
    "        for param_type, count in param_counts.items():\n",
    "            print(f\"     {param_type}: {count:,}\")\n",
    "    \n",
    "    print(\"\\n✅ System information displayed!\")\n",
    "\n",
    "# Display system information\n",
    "display_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Quick Start Guide\n",
    "\n",
    "### **To run this notebook on GPU cloud services:**\n",
    "\n",
    "1. **Lambda Labs** (Recommended)\n",
    "   - Choose RTX A6000 instance\n",
    "   - Upload this notebook and required files\n",
    "   - Run cells sequentially\n",
    "\n",
    "2. **Vast.ai** (Cheapest)\n",
    "   - Rent RTX 4090 instance\n",
    "   - Use PyTorch Docker image\n",
    "   - Upload and run notebook\n",
    "\n",
    "3. **Google Colab Pro** (Easiest)\n",
    "   - Upload to Google Drive\n",
    "   - Open in Colab with GPU runtime\n",
    "   - Mount Drive and run\n",
    "\n",
    "### **Expected Costs:**\n",
    "- **Lambda Labs**: ~$0.60/hour = ~$6-12 for full training\n",
    "- **Vast.ai**: ~$0.30/hour = ~$3-6 for full training\n",
    "- **Colab Pro**: $10/month unlimited\n",
    "\n",
    "### **Training Time:**\n",
    "- **RTX A6000**: ~6-8 hours\n",
    "- **RTX 4090**: ~8-12 hours\n",
    "- **A100**: ~4-6 hours\n",
    "\n",
    "### **Files Needed:**\n",
    "- `enhanced_transformer_training.ipynb` (this notebook)\n",
    "- `transformer_enhanced_v2.py` (enhanced model)\n",
    "- `enhanced_features.py` (feature engineering)\n",
    "- `crypto_5min_2years.csv` (training data)\n",
    "\n",
    "### **To Start Training:**\n",
    "1. Run all cells above sequentially\n",
    "2. Uncomment the last line in the \"Start Training\" cell\n",
    "3. Execute the training cell\n",
    "4. Monitor progress and results\n",
    "\n",
    "### **After Training:**\n",
    "- Model saved as `enhanced_transformer_best.pth`\n",
    "- Training plots saved as `training_results.png`\n",
    "- Use model for inference and trading signals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}