# Section 1: Environment Setup and Dependencies - FIXED VERSION
import sys
import os
from pathlib import Path

# Add paths safely
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir.parent))
sys.path.insert(0, str(current_dir.parent.parent))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Core ML libraries
import torch
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import EvalCallback

# Statistical analysis (with error handling)
try:
    from scipy import stats
    from sklearn.metrics import mean_squared_error, mean_absolute_error
    print("‚úÖ Statistical libraries loaded")
except ImportError as e:
    print(f"‚ö†Ô∏è Optional statistical library missing: {e}")
    stats = None

# Optional optimization library
try:
    import optuna
    print("‚úÖ Optuna optimization available")
except ImportError:
    print("‚ö†Ô∏è Optuna not available - hyperparameter optimization disabled")
    optuna = None

# FinRL preprocessor (only what we need)
try:
    from finrl.meta.preprocessor.yahoodownloader import YahooDownloader
    from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split
    print("‚úÖ FinRL preprocessors loaded")
except ImportError as e:
    print(f"‚ùå FinRL import error: {e}")

# MOST IMPORTANT: Use our comprehensive patch instead of buggy original FinRL
from finrl_comprehensive_patch import create_safe_finrl_env, safe_backtest_model

# Configure plotting safely
try:
    plt.style.use('seaborn-v0_8')
except OSError:
    try:
        plt.style.use('seaborn')
    except OSError:
        print("‚ö†Ô∏è Using default matplotlib style")

sns.set_palette("plasma")
plt.rcParams['figure.figsize'] = (14, 10)
plt.rcParams['font.size'] = 12

# Check PyTorch device
if torch.backends.mps.is_available():
    device = 'mps'
    print("üöÄ Using Apple Silicon MPS GPU")
elif torch.cuda.is_available():
    device = 'cuda'
    print("üöÄ Using NVIDIA CUDA GPU")
else:
    device = 'cpu'
    print("üñ•Ô∏è Using CPU")

print("‚úÖ Environment setup complete for Cardano (ADA) trading")
print("üîß Using comprehensive FinRL patch for error-free training")
print(f"‚ö° Compute device: {device}")